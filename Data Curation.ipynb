{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DATA CURATION PROJECT \n",
    "<h2> Created by : Malhar Patwari <br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "from collections import Counter\n",
    "import requests\n",
    "import geocoder\n",
    "#import zipcode\n",
    "from uszipcode import ZipcodeSearchEngine   #Install this library using !pip install uszipcode\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Input Data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inspection ID</th>\n",
       "      <th>DBA Name</th>\n",
       "      <th>AKA Name</th>\n",
       "      <th>License #</th>\n",
       "      <th>Facility Type</th>\n",
       "      <th>Risk</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Inspection Date</th>\n",
       "      <th>Inspection Type</th>\n",
       "      <th>Results</th>\n",
       "      <th>Violations</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3785</th>\n",
       "      <td>2145472</td>\n",
       "      <td>SANDUNGA</td>\n",
       "      <td>SANDUNGA</td>\n",
       "      <td>2157363</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>Risk 1 (High)</td>\n",
       "      <td>2619 W LAWRENCE AVE</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>IL</td>\n",
       "      <td>60625</td>\n",
       "      <td>2018-02-23</td>\n",
       "      <td>Canvass</td>\n",
       "      <td>Pass</td>\n",
       "      <td>34. FLOORS: CONSTRUCTED PER CODE, CLEANED, GOO...</td>\n",
       "      <td>41.9684544486365</td>\n",
       "      <td>-87.6946199150986</td>\n",
       "      <td>(41.96845444863656, -87.69461991509863)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3786</th>\n",
       "      <td>2135864</td>\n",
       "      <td>SANOS PIZZERIA</td>\n",
       "      <td>SANOS PIZZERIA</td>\n",
       "      <td>3663</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>Risk 1 (High)</td>\n",
       "      <td>4469 W LAWRENCE AVE</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>IL</td>\n",
       "      <td>60630</td>\n",
       "      <td>2018-01-23</td>\n",
       "      <td>Canvass</td>\n",
       "      <td>No Entry</td>\n",
       "      <td>36. LIGHTING: REQUIRED MINIMUM FOOT-CANDLES OF...</td>\n",
       "      <td>41.9679942418708</td>\n",
       "      <td>-87.7406431600631</td>\n",
       "      <td>(41.96799424187085, -87.74064316006319)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>2136010</td>\n",
       "      <td>SANTORINI</td>\n",
       "      <td>SANTORINI</td>\n",
       "      <td>42683</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>Risk 1 (High)</td>\n",
       "      <td>138 S HALSTED ST</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>IL</td>\n",
       "      <td>60661</td>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>Canvass Re-Inspection</td>\n",
       "      <td>Pass</td>\n",
       "      <td>34. FLOORS: CONSTRUCTED PER CODE, CLEANED, GOO...</td>\n",
       "      <td>41.8792779138802</td>\n",
       "      <td>-87.6474292960897</td>\n",
       "      <td>(41.87927791388022, -87.64742929608974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>2135414</td>\n",
       "      <td>SANTORINI</td>\n",
       "      <td>SANTORINI</td>\n",
       "      <td>42683</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>Risk 1 (High)</td>\n",
       "      <td>138 S HALSTED ST</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>IL</td>\n",
       "      <td>60661</td>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>Canvass</td>\n",
       "      <td>Fail</td>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "      <td>41.8792779138802</td>\n",
       "      <td>-87.6474292960897</td>\n",
       "      <td>(41.87927791388022, -87.64742929608974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>2159596</td>\n",
       "      <td>SAPORI</td>\n",
       "      <td>SAPORI</td>\n",
       "      <td>2320734</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>Risk 1 (High)</td>\n",
       "      <td>2701 N HALSTED ST</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>IL</td>\n",
       "      <td>60614</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>Canvass</td>\n",
       "      <td>Pass</td>\n",
       "      <td>30. FOOD IN ORIGINAL CONTAINER, PROPERLY LABEL...</td>\n",
       "      <td>41.9315784967167</td>\n",
       "      <td>-87.6488249393655</td>\n",
       "      <td>(41.93157849671675, -87.64882493936558)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Inspection ID        DBA Name        AKA Name  License # Facility Type  \\\n",
       "3785        2145472        SANDUNGA        SANDUNGA    2157363    Restaurant   \n",
       "3786        2135864  SANOS PIZZERIA  SANOS PIZZERIA       3663    Restaurant   \n",
       "3787        2136010       SANTORINI       SANTORINI      42683    Restaurant   \n",
       "3788        2135414       SANTORINI       SANTORINI      42683    Restaurant   \n",
       "3789        2159596          SAPORI          SAPORI    2320734    Restaurant   \n",
       "\n",
       "               Risk               Address     City State    Zip  \\\n",
       "3785  Risk 1 (High)  2619 W LAWRENCE AVE   CHICAGO    IL  60625   \n",
       "3786  Risk 1 (High)  4469 W LAWRENCE AVE   CHICAGO    IL  60630   \n",
       "3787  Risk 1 (High)     138 S HALSTED ST   CHICAGO    IL  60661   \n",
       "3788  Risk 1 (High)     138 S HALSTED ST   CHICAGO    IL  60661   \n",
       "3789  Risk 1 (High)    2701 N HALSTED ST   CHICAGO    IL  60614   \n",
       "\n",
       "     Inspection Date        Inspection Type   Results  \\\n",
       "3785      2018-02-23                Canvass      Pass   \n",
       "3786      2018-01-23                Canvass  No Entry   \n",
       "3787      2018-01-25  Canvass Re-Inspection      Pass   \n",
       "3788      2018-01-12                Canvass      Fail   \n",
       "3789      2018-04-05                Canvass      Pass   \n",
       "\n",
       "                                             Violations          Latitude  \\\n",
       "3785  34. FLOORS: CONSTRUCTED PER CODE, CLEANED, GOO...  41.9684544486365   \n",
       "3786  36. LIGHTING: REQUIRED MINIMUM FOOT-CANDLES OF...  41.9679942418708   \n",
       "3787  34. FLOORS: CONSTRUCTED PER CODE, CLEANED, GOO...  41.8792779138802   \n",
       "3788  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...  41.8792779138802   \n",
       "3789  30. FOOD IN ORIGINAL CONTAINER, PROPERLY LABEL...  41.9315784967167   \n",
       "\n",
       "              Longitude                                 Location  \n",
       "3785  -87.6946199150986  (41.96845444863656, -87.69461991509863)  \n",
       "3786  -87.7406431600631  (41.96799424187085, -87.74064316006319)  \n",
       "3787  -87.6474292960897  (41.87927791388022, -87.64742929608974)  \n",
       "3788  -87.6474292960897  (41.87927791388022, -87.64742929608974)  \n",
       "3789  -87.6488249393655  (41.93157849671675, -87.64882493936558)  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting data from CSV\n",
    "data = pd.read_excel(\"Data.xlsx\",dtype={'Zip':'str','Latitude':'str','Longitude':'str','Location':'str'}) #Note: read zip,lat,log in string\n",
    "data.head()\n",
    "#data['Zip'][data['Zip']==\"nan\"]\n",
    "#print(data[data[\"Zip\"].isnull()])\n",
    "df = pd.DataFrame(data)\n",
    "df['Zip'][df['Zip'] == 'nan'] = None\n",
    "df['Latitude'][df['Latitude'] == 'nan'] = None\n",
    "df['Longitude'][df['Longitude'] == 'nan'] = None\n",
    "df['Location'][df['Location'] == 'nan'] = None\n",
    "#df['Zip']=df['Zip'].astype(int)\n",
    "#df['Zip'] = list(map(int,df['Zip']))\n",
    "df[3785:3790]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> User Defined Functions for Google API and Edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to calculate edit distance between two strings\n",
    "def edit(s, t):\n",
    "    if s == \"\":\n",
    "        return len(t)\n",
    "    if t == \"\":\n",
    "        return len(s)\n",
    "    if s[-1] == t[-1]:\n",
    "        cost = 0\n",
    "    else:\n",
    "        cost = 1\n",
    "       \n",
    "    res = min([edit(s[:-1], t)+1,\n",
    "               edit(s, t[:-1])+1, \n",
    "               edit(s[:-1], t[:-1]) + cost])\n",
    "    return res\n",
    "\n",
    "def get_city_by_api(z):\n",
    "    r = requests.get(\"https://maps.googleapis.com/maps/api/geocode/json?address=\"+z+\"&sensor=true&key=AIzaSyC8UyUnx2LZn1jiSNIC4DPXfP3gtI2RUMY\")\n",
    "    r = r.json()\n",
    "    if(r['status']==\"OK\"):\n",
    "        a = r['results'][0]['address_components']\n",
    "        for i in a:        \n",
    "            if(i['types'][0]==\"locality\"):\n",
    "                name= i['long_name']\n",
    "                print(\"API USED\")\n",
    "                break\n",
    "        name =name.lower()\n",
    "        return name\n",
    "    else:\n",
    "        return \"ERROR\"\n",
    "\n",
    "def get_state_by_api(z):\n",
    "    r = requests.get(\"https://maps.googleapis.com/maps/api/geocode/json?address=\"+z+\"&sensor=true&key=AIzaSyC8UyUnx2LZn1jiSNIC4DPXfP3gtI2RUMY\")\n",
    "    r = r.json()\n",
    "    if(r['status']==\"OK\"):\n",
    "        a = r['results'][0]['address_components']\n",
    "        for i in a:        \n",
    "            if(i['types'][0]==\"administrative_area_level_1\"):\n",
    "                name= i['short_name']\n",
    "                print(\"API USED\")\n",
    "                break\n",
    "        name =name.upper()\n",
    "        return name\n",
    "    else:\n",
    "        return \"ERROR\"\n",
    "\n",
    "def get_city_by_api_loc(lat,log):\n",
    "    r = requests.get(\"https://maps.googleapis.com/maps/api/geocode/json?latlng=\"+lat+\",\"+log+\"&sensor=true&key=AIzaSyC8UyUnx2LZn1jiSNIC4DPXfP3gtI2RUMY\")\n",
    "    r = r.json()\n",
    "    if(r['status']==\"OK\"):\n",
    "        a = r['results'][0]['address_components']\n",
    "        for i in a:        \n",
    "            if(i['types'][0]==\"locality\"):\n",
    "                name= i['long_name']\n",
    "                print(\"API USED\")\n",
    "                break\n",
    "        name =name.lower()\n",
    "        return name\n",
    "    else:\n",
    "        return \"ERROR\"\n",
    "\n",
    "def get_state_by_api_loc(lat,log):\n",
    "    r = requests.get(\"https://maps.googleapis.com/maps/api/geocode/json?latlng=\"+lat+\",\"+log+\"&sensor=true&key=AIzaSyC8UyUnx2LZn1jiSNIC4DPXfP3gtI2RUMY\")\n",
    "    r = r.json()\n",
    "    if(r['status']==\"OK\"):\n",
    "        a = r['results'][0]['address_components']\n",
    "        for i in a:        \n",
    "            if(i['types'][0]==\"administrative_area_level_1\"):\n",
    "                name= i['short_name']\n",
    "                print(\"API USED\")\n",
    "                break\n",
    "        name =name.upper()\n",
    "        return name\n",
    "    else:\n",
    "        return \"ERROR\"\n",
    "    \n",
    "def get_zip_by_api_loc(lat,log):\n",
    "    r = requests.get(\"https://maps.googleapis.com/maps/api/geocode/json?latlng=\"+lat+\",\"+log+\"&sensor=true&key=AIzaSyC8UyUnx2LZn1jiSNIC4DPXfP3gtI2RUMY\")\n",
    "    r = r.json()\n",
    "    if(r['status']==\"OK\"):\n",
    "        a = r['results'][0]['address_components']\n",
    "        for i in a:        \n",
    "            if(i['types'][0]==\"postal_code\"):\n",
    "                name= i['long_name']\n",
    "                print(\"API USED\")\n",
    "                break        \n",
    "        return name\n",
    "    else:\n",
    "        return \"ERROR\"    \n",
    "    \n",
    "def get_zip_by_api(add):\n",
    "    r = requests.get(\"https://maps.googleapis.com/maps/api/geocode/json?address=\"+add+\"&sensor=true&key=AIzaSyC8UyUnx2LZn1jiSNIC4DPXfP3gtI2RUMY\")\n",
    "    r = r.json()\n",
    "    if(r['status']==\"OK\"):\n",
    "        a = r['results'][0]['address_components']\n",
    "        for i in a:        \n",
    "            if(i['types'][0]==\"postal_code\"):\n",
    "                name= i['long_name']\n",
    "                print(\"API USED\")\n",
    "                break        \n",
    "        return name\n",
    "    else:\n",
    "        return \"ERROR\"\n",
    "    \n",
    "def get_latitude_by_api(add):\n",
    "    r = requests.get(\"https://maps.googleapis.com/maps/api/geocode/json?address=\"+add+\"&sensor=true&key=AIzaSyC8UyUnx2LZn1jiSNIC4DPXfP3gtI2RUMY\")\n",
    "    r = r.json()\n",
    "    if(r['status']==\"OK\"):\n",
    "        a = r['results'][0]['geometry']['location']['lat']\n",
    "        a = str(a)\n",
    "        print(a)\n",
    "        return a\n",
    "    else:\n",
    "        return \"ERROR\"\n",
    "    \n",
    "def get_longitude_by_api(add):\n",
    "    r = requests.get(\"https://maps.googleapis.com/maps/api/geocode/json?address=\"+add+\"&sensor=true&key=AIzaSyC8UyUnx2LZn1jiSNIC4DPXfP3gtI2RUMY\")\n",
    "    r = r.json()\n",
    "    if(r['status']==\"OK\"):\n",
    "        a = r['results'][0]['geometry']['location']['lng']\n",
    "        a = str(a)\n",
    "        print(a)\n",
    "        return a\n",
    "    else:\n",
    "        return \"ERROR\"\n",
    "\n",
    "def get_add_by_api_loc(lat,log):\n",
    "    r = requests.get(\"https://maps.googleapis.com/maps/api/geocode/json?latlng=\"+lat+\",\"+log+\"&sensor=true&key=AIzaSyC8UyUnx2LZn1jiSNIC4DPXfP3gtI2RUMY\")\n",
    "    r = r.json()\n",
    "    if(r['status']==\"OK\"):\n",
    "        a = r['results'][0]['address_components']\n",
    "        for i in a:            \n",
    "            if(i['types'][0] == \"street_number\"):\n",
    "                street_num = i['long_name']\n",
    "            if(i['types'][0] == \"route\"):\n",
    "                route = i['long_name']\n",
    "            if(i['types'][0] == \"neighborhood\"):\n",
    "                neighborhood = i['long_name']    \n",
    "        name= street_num + \" \" + route + \" \" + neighborhood       \n",
    "        return name        \n",
    "        \n",
    "    else:\n",
    "        return \"ERROR\"   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Replacing Null values on \"Inspection Id\" attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all null value indices:\n",
      "Int64Index([], dtype='int64')\n",
      "all null values must be replaced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Null error detection for Inspectionid: \n",
    "\n",
    "print(\"all null value indices:\")\n",
    "null_index_inspec = df[df['Inspection ID'].isnull()].index\n",
    "print(null_index_inspec)\n",
    "\n",
    "#if duplicated values then replace ids with 0\n",
    "df['Inspection ID'][df['Inspection ID'].duplicated()] = 0\n",
    "\n",
    "#replacing nulls with 0\n",
    "for i in null_index_inspec:\n",
    "    df['Inspection ID'][i] = 0\n",
    "        \n",
    "        \n",
    "print(\"all null values must be replaced\")       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Replacing Null values on \"License#\" attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All null value indices\n",
      "Int64Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# Null error detection for License#: \n",
    "print(\"All null value indices\")\n",
    "null_index_license = df[df['License #'].isnull()].index\n",
    "print(null_index_license)\n",
    "\n",
    "#Replacing nulls with 0\n",
    "for i in null_index_license:\n",
    "    df['License #'][i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Replacing Null values on Inspection Date and Inspection Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n",
      "Int64Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# Null error detection for Inspection date and Inspection Type: \n",
    "null_index_indate = df[df['Inspection Date'].isnull()].index\n",
    "print(null_index_indate)\n",
    "\n",
    "null_index_intype = df[df['Inspection Type'].isnull()].index\n",
    "print(null_index_intype)\n",
    "\n",
    "#Replacing nulls in Inspection date and type with \"NA\"\n",
    "for i in null_index_indate:\n",
    "    df['Inspection Date'][i] = \"NA\"\n",
    "for i in null_index_intype:\n",
    "    df['Inspection Type'][i] = \"NA\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Replacing Null values on Results attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# Null error detection for Results: \n",
    "null_index_result = df[df['Results'].isnull()].index\n",
    "print(null_index_result)\n",
    "\n",
    "#Replacing nulls in results with \"No Entry\"\n",
    "for i in null_index_result:\n",
    "    df['Results'][i] = \"No Entry\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Replacing Null Values on Violations attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n",
      "Series([], Name: Violations, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "# Null error detection for Violations: \n",
    "null_index_violations = df[df['Violations'].isnull()].index\n",
    "print(null_index_violations)\n",
    "\n",
    "#Replacing nulls in results with \"NA\"\n",
    "for i in null_index_violations:\n",
    "    df['Violations'][i] = \"NA\"\n",
    "\n",
    "\n",
    "print(df['Violations'][null_index_violations])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Replacing Nulls on \"Risk\" Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([45, 46], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45    NA\n",
       "46    NA\n",
       "Name: Risk, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detecting nulls in Risk field\n",
    "null_index_risk = df[df['Risk'].isnull()].index\n",
    "print(null_index_risk)\n",
    "\n",
    "#removal of nulls with \"NA\" for risk\n",
    "for i in null_index_risk:\n",
    "    df['Risk'][i] = \"NA\"\n",
    "\n",
    "df['Risk'][null_index_risk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Replacing Nulls on \"Facility Type\" attribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n",
      "ALL NULL Values are REPLACED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: Facility Type, dtype: object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#error 2 detection for Facility types\n",
    "null_index_facility = df[df['Facility Type'].isnull()].index\n",
    "print(null_index_facility)\n",
    "#df[45:50]\n",
    "\n",
    "#Solve Nulls for Facility Type\n",
    "for i in null_index_facility:    \n",
    "    if(df['DBA Name'][i]!=None):                        \n",
    "        Dname = df['DBA Name'][i]\n",
    "        #print(Dname)\n",
    "        li = df[df['DBA Name'] == Dname].index\n",
    "        #print(li)\n",
    "        if(len(li)==1):  # this is if the dba name is unique\n",
    "            df['Facility Type'][i] = \"NA\"\n",
    "        else:            #this is if DBA name is not unique i.e. it is a new name\n",
    "            all_names = df['Facility Type'][li]\n",
    "            all_names_set = set(all_names)\n",
    "            print(all_names_set)\n",
    "            if((len(all_names_set) == 1)and(next(iter(all_names_set))!=None)):    #if all has same facility type\n",
    "                df['Facility Type'][i] = all_names_set.pop()\n",
    "            else:                           #if different facility types\n",
    "                c = Counter(all_names)\n",
    "          #      print(c)\n",
    "                if(c.most_common()[0][1] >int(len(li)/2)):   # 50% enough frequency to assign facility type\n",
    "                    df['Facility Type'][i] = c.most_common()[0][0]\n",
    "                else:                        #not enough frequency so assign its own dba name \n",
    "                    df['Facility Type'][i] = \"NA\"\n",
    "    else:\n",
    "        df['Facility Type'][i]=\"NA\"\n",
    "\n",
    "df['Facility Type'][df['Facility Type'].isnull()] = \"NA\" #this will replace all remaining nulls with \"NA\"\n",
    "\n",
    "print(\"ALL NULL Values are REPLACED\")\n",
    "#all null solved for Facility in df.\n",
    "df['Facility Type'][null_index_facility]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Replacing Null Values on Attribute DBA Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n",
      "All nulls have been replaced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inspection ID</th>\n",
       "      <th>DBA Name</th>\n",
       "      <th>AKA Name</th>\n",
       "      <th>License #</th>\n",
       "      <th>Facility Type</th>\n",
       "      <th>Risk</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Inspection Date</th>\n",
       "      <th>Inspection Type</th>\n",
       "      <th>Results</th>\n",
       "      <th>Violations</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Inspection ID, DBA Name, AKA Name, License #, Facility Type, Risk, Address, City, State, Zip, Inspection Date, Inspection Type, Results, Violations, Latitude, Longitude, Location]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null error detection for DBA Name: \n",
    "\n",
    "\n",
    "null_index_dba = df[df['DBA Name'].isnull()].index\n",
    "print(null_index_dba)\n",
    "\n",
    "\n",
    "#Solve Nulls for DBA Names \n",
    "for i in null_index_dba:\n",
    "    if(df['AKA Name']!= None):\n",
    "        Aname = df['AKA Name'][i]\n",
    "        #print(Aname)\n",
    "        li = df[df['AKA Name'] == Aname].index\n",
    "        print(li)\n",
    "        if(len(li)==1):  # this is if the AKA name is unique\n",
    "            df['DBA Name'][i] = df['AKA Name'][i]\n",
    "        else:            #this is if AKA name is not unique\n",
    "            all_names = df['DBA Name'][li]\n",
    "            all_names_set = set(all_names)\n",
    "            print(all_names_set)\n",
    "            if((len(all_names_set) == 1)and(next(iter(all_names_set))!=None)):    #if all has same aka name            \n",
    "                df['DBA Name'][i] = all_names_set.pop()\n",
    "            else:                           #if different dba names\n",
    "                c = Counter(all_names)\n",
    "                print(c)\n",
    "                if(c.most_common()[0][1] >int(len(li)/2)):   # 50% enough frequency to assign aka name\n",
    "                    df['DBA Name'][i] = c.most_common()[0][0]\n",
    "                else:                        #not enough frequency so assign its own aka name \n",
    "                    df['DBA Name'][i] = df['AKA Name'][i]\n",
    "    else:\n",
    "        df['DBA Name'][i] = \"NA\"\n",
    "\n",
    "df['DBA Name'][df['DBA Name'].isnull()] = df['AKA Name'][df['DBA Name'].isnull()] #This will replace all null with its DBA name\n",
    "#df[1214:1216]\n",
    "print(\"All nulls have been replaced\")\n",
    "#all null solved for DBA Names in df.\n",
    "df[df['DBA Name'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Replacing all Null values on AKA Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([  71,  167,  338,  463,  500, 1120, 1143, 1214, 2281, 2336, 2337,\n",
      "            2564, 2601, 2832, 2918, 3150, 3434, 3435, 3586, 3643, 3980, 3986,\n",
      "            4513, 4607, 4619, 4620],\n",
      "           dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Nullsa have been replaced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71                A & S FOOD MART # 1,INC\n",
       "167              AMORINO WATER TOWER, LLC\n",
       "338                     BARWAQO KABOB ONE\n",
       "463                                 BONCI\n",
       "500     BRIGHT HORIZONS CHICAGO WEST LOOP\n",
       "1120               DIVISION MINI MART INC\n",
       "1143                  DOLLAR TREE  # 4143\n",
       "1214                        DUNKIN DONUTS\n",
       "2281                            K-KITCHEN\n",
       "2336                   LA CASA DEL BUFFET\n",
       "2337                   LA CASA DEL BUFFET\n",
       "2564                         LOTUS GARDEN\n",
       "2601                       M G BIEN ESTAR\n",
       "2832                     MEMO'S CARAMELOS\n",
       "2918                          MOORE HOUSE\n",
       "3150                        ONE STOP FOOD\n",
       "3434                  POKEWORKS CHICAGO 2\n",
       "3435                  POKEWORKS CHICAGO 2\n",
       "3586                      RAMIREZ GROCERY\n",
       "3643                REVEL  DOWNTOWN, LLC.\n",
       "3980          SOUTHEAST ELEMENTARY SCHOOL\n",
       "3986                             SPACE519\n",
       "4513                       THE HALAL GUYS\n",
       "4607              THOMAS HOYNE ELEMENTARY\n",
       "4619                  TIENTSIN RESTAURANT\n",
       "4620                  TIENTSIN RESTAURANT\n",
       "Name: AKA Name, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TASK1 Null error detection for AKA Name: \n",
    "\n",
    "null_index = df[df['AKA Name'].isnull()].index\n",
    "print(null_index)\n",
    "    \n",
    "\n",
    "#Solve Nulls for AKA Names \n",
    "for i in null_index:\n",
    "    if(df['DBA Name'][i]!=None):\n",
    "        if(df['DBA Name'][i]==\"NA\"):\n",
    "            df['AKA Name'][i] = \"NA\"\n",
    "        else:\n",
    "            Dname = df['DBA Name'][i]\n",
    "            #print(Dname)\n",
    "            li = df[df['DBA Name'] == Dname].index\n",
    "            #print(li)\n",
    "            if(len(li)==1):  # this is if the dba name is unique\n",
    "                df['AKA Name'][i] = df['DBA Name'][i]\n",
    "            else:            #this is if DBA name is not unique\n",
    "                all_names = df['AKA Name'][li]\n",
    "                all_names_set = set(all_names)\n",
    "                #print(all_names_set)\n",
    "                if((len(all_names_set) == 1)and(next(iter(all_names_set))!=None)):    #if all has same dba name            \n",
    "                    df['AKA Name'][i] = all_names_set.pop()\n",
    "                else:                           #if different dba names\n",
    "                    c = Counter(all_names)\n",
    "                    #print(c)\n",
    "                    if(c.most_common()[0][1] >int(len(li)/2)):   # 50% enough frequency to assign dba name\n",
    "                        df['AKA Name'][i] = c.most_common()[0][0]\n",
    "                    else:                        #not enough frequency so assign its own dba name \n",
    "                        df['AKA Name'][i] = df['DBA Name'][i]\n",
    "    else:\n",
    "        df['AKA Name'][i] = \"NA\"\n",
    "\n",
    "df['AKA Name'][df['AKA Name'].isnull()] = df['DBA Name'][df['AKA Name'].isnull()] #This will replace all null with its DBA name\n",
    "df[1214:1216]\n",
    "print(\"All Nullsa have been replaced\")\n",
    "#all null solved for AKA Names in df.\n",
    "df[\"AKA Name\"][null_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Replacing all Nulls on Address Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n",
      "ALL Address attribute values have been replaced\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: Address, dtype: object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detection for Address\n",
    "null_index_add = df[df['Address'].isnull()].index\n",
    "print(null_index_add)\n",
    "\n",
    "\n",
    "for i in null_index_add:\n",
    "    if((df['Latitude'][i]!=None)and(df['Longitude'][i]!=None)):            #This if is to identify on basis of lat andlog\n",
    "        lat = df['Latitude'][i]\n",
    "        log = df['Longitude'][i]       \n",
    "        a = get_add_by_api_loc(lat,log) #uses google api to get City\n",
    "        if(a==\"ERROR\"):\n",
    "            print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "            df['Address'][i] = \"NA\"\n",
    "        else:\n",
    "            df['Address'][i] = a\n",
    "            print(df['Address'][i])\n",
    "            print(\"Used Google API\")\n",
    "    else:                                                                 #if not location, put NA instead\n",
    "        df['Address'][i] = \"NA\"\n",
    "        \n",
    "print(\"ALL Address attribute values have been replaced\")        \n",
    "#show null addresses \n",
    "df['Address'][null_index_add]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Replacing all Nulls on City Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([337, 505, 2004, 2005], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inspection ID</th>\n",
       "      <th>DBA Name</th>\n",
       "      <th>AKA Name</th>\n",
       "      <th>License #</th>\n",
       "      <th>Facility Type</th>\n",
       "      <th>Risk</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Inspection Date</th>\n",
       "      <th>Inspection Type</th>\n",
       "      <th>Results</th>\n",
       "      <th>Violations</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Inspection ID, DBA Name, AKA Name, License #, Facility Type, Risk, Address, City, State, Zip, Inspection Date, Inspection Type, Results, Violations, Latitude, Longitude, Location]\n",
       "Index: []"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detection for City\n",
    "null_index_City = df[df['City'].isnull()].index\n",
    "print(null_index_City)\n",
    "\n",
    "#Error4 removing nulls from city\n",
    "search = ZipcodeSearchEngine()\n",
    "\n",
    "for i in null_index_City:\n",
    "    \n",
    "    if(df['Zip'][i]!= None):   #This if is to identify on basis of zipcode\n",
    "        zzip = df['Zip'][i] \n",
    "        #print(zzip)        \n",
    "        #print(i)\n",
    "        li = list(df[df['Zip'] == zzip].index)\n",
    "        #print(li)\n",
    "        li.remove(i)\n",
    "        #print(li)   \n",
    "        \n",
    "        if(li == None):  # this is if the zip is unique\n",
    "            if(((search.by_zipcode(zzip)).City)!= None):\n",
    "                df['City'][i] = ((search.by_zipcode(zzip)).City).lower() #this will assign city using library\n",
    "                #print(df['City'][i])\n",
    "                print(\"Successsful\")\n",
    "            else:\n",
    "                a = get_city_by_api(zzip) #uses google api to get City\n",
    "                if(a==\"ERROR\"):\n",
    "                    print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "                    df['City'][i] = \"NA\"\n",
    "                else:\n",
    "                    df['City'][i] = a\n",
    "                  #  print(df['City'][i])\n",
    "                    print(\"Used Google API\")\n",
    "                    \n",
    "        else:                                           #this is if zip is not unique\n",
    "            all_names = df['City'][li]\n",
    "            all_names_set = set(all_names)\n",
    "         #   print(all_names_set)\n",
    "            if((len(all_names_set) == 1)and(next(iter(all_names_set))!=None)):    #if all has same City\n",
    "                df['City'][i] = all_names_set.pop()\n",
    "            else:                           #if different City\n",
    "                if(((search.by_zipcode(zzip)).City)!= None):\n",
    "                    df['City'][i] = ((search.by_zipcode(zzip)).City).lower() #this will assign city using library                \n",
    "                else:\n",
    "                    a = get_city_by_api(zzip) #uses google api to get City\n",
    "                    if(a==\"ERROR\"):\n",
    "                        print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "                        df['City'][i] = \"NA\"\n",
    "                    else:\n",
    "                        df['City'][i] = a\n",
    "                        \n",
    "    elif((df['Latitude'][i]!=None)and(df['Longitude'][i]!=None)):            #This if is to identify on basis of lat andlog\n",
    "        lat = df['Latitude'][i]\n",
    "        log = df['Longitude'][i]       \n",
    "        a = get_city_by_api_loc(lat,log) #uses google api to get City\n",
    "        if(a==\"ERROR\"):\n",
    "            print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "            df['City'][i] = \"NA\"\n",
    "        else:\n",
    "            df['City'][i] = a\n",
    "            print(df['City'][i])\n",
    "            print(\"Used Google API\")  \n",
    "            \n",
    "    elif(df['Address'][i]!=None):            #This if is to identify on basis of Address\n",
    "        add = df['Address'][i] \n",
    "        print(add)\n",
    "        li = list(df[df['Address'] == add].index)\n",
    "        li.remove(i)\n",
    "        print(li)\n",
    "        if(li == None):  # this is if the Address is unique\n",
    "            a = get_city_by_api(add) #uses google api to get City\n",
    "            if(a==\"ERROR\"):\n",
    "                print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "                df['City'][i] = \"NA\"\n",
    "            else:\n",
    "                df['City'][i] = a\n",
    "                print(df['City'][i])\n",
    "                print(\"Used Google API\")\n",
    "                \n",
    "        else:                                           #this is if Address is not unique\n",
    "            all_names = df['City'][li]\n",
    "            all_names_set = set(all_names)\n",
    "            print(all_names_set)\n",
    "            if((len(all_names_set) == 1)and(next(iter(all_names_set))!=None)):    #if all has same City\n",
    "                df['City'][i] = all_names_set.pop()\n",
    "            else:                           #if different City\n",
    "                a = get_city_by_api(add) #uses google api to get City\n",
    "                if(a==\"ERROR\"):\n",
    "                    print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "                    df['City'][i] = \"NA\"\n",
    "                else:\n",
    "                    df['City'][i] = a\n",
    "                    \n",
    "    else:\n",
    "        print(\"No data is there on the basis of which city can be found\")\n",
    "        print(\"So putting NA as a City\")\n",
    "        df['City'][i] = \"NA\"\n",
    "\n",
    "\n",
    "\n",
    "#see all remaining nulls in city\n",
    "#df[2001:2015]\n",
    "df[df['City'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Used edit distance to replacing Typos in City Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inspection ID</th>\n",
       "      <th>DBA Name</th>\n",
       "      <th>AKA Name</th>\n",
       "      <th>License #</th>\n",
       "      <th>Facility Type</th>\n",
       "      <th>Risk</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Inspection Date</th>\n",
       "      <th>Inspection Type</th>\n",
       "      <th>Results</th>\n",
       "      <th>Violations</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Inspection ID, DBA Name, AKA Name, License #, Facility Type, Risk, Address, City, State, Zip, Inspection Date, Inspection Type, Results, Violations, Latitude, Longitude, Location]\n",
       "Index: []"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert characters into lower case\n",
    "df['City']=[str(x).lower() for x in df['City']]\n",
    "\n",
    "# first clean data using edit distance to clean any typos in City.\n",
    "\n",
    "for i in df['City'].index:    \n",
    "    if(df['City'][i] != \"chicago\"):\n",
    "        if(edit(df['City'][i],\"chicago\")<3):            \n",
    "            df['City'][i]=\"chicago\"\n",
    "        else:            \n",
    "            continue\n",
    "    else:\n",
    "        continue\n",
    "df['City'].unique()\n",
    "\n",
    "\n",
    "df[df['City'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Replacing all Nulls on State Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([2004, 2005], dtype='int64')\n",
      "all Nulls are replaced for State Attribute\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inspection ID</th>\n",
       "      <th>DBA Name</th>\n",
       "      <th>AKA Name</th>\n",
       "      <th>License #</th>\n",
       "      <th>Facility Type</th>\n",
       "      <th>Risk</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Inspection Date</th>\n",
       "      <th>Inspection Type</th>\n",
       "      <th>Results</th>\n",
       "      <th>Violations</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Inspection ID, DBA Name, AKA Name, License #, Facility Type, Risk, Address, City, State, Zip, Inspection Date, Inspection Type, Results, Violations, Latitude, Longitude, Location]\n",
       "Index: []"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#error5 detection for State\n",
    "null_index_State = df[df['State'].isnull()].index\n",
    "print(null_index_State)\n",
    "\n",
    "#Error5 removing nulls from State\n",
    "search = ZipcodeSearchEngine()\n",
    "\n",
    "for i in null_index_State:\n",
    "    \n",
    "    if(df['Zip'][i]!= None):   #This if is to identify on basis of zipcode\n",
    "        zzip = df['Zip'][i] \n",
    "        #print(zzip)        \n",
    "        #print(i)\n",
    "        li = list(df[df['Zip'] == zzip].index)\n",
    "        #print(li)\n",
    "        li.remove(i)\n",
    "        #print(li)   \n",
    "        if(li == None):  # this is if the zip is unique\n",
    "            if(((search.by_zipcode(zzip)).State)!= None):     #if library has answer\n",
    "                df['State'][i] = ((search.by_zipcode(zzip)).State).upper()    #this will assign State using library\n",
    "                #print(df['State'][i])\n",
    "                print(\"Successsful\")\n",
    "            else:                                             #if library has no answer\n",
    "                a = get_state_by_api(zzip) #uses google api to get State\n",
    "                if(a==\"ERROR\"):\n",
    "                    print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "                    df['State'][i] = \"NA\"\n",
    "                else:\n",
    "                    df['State'][i] = a\n",
    "                 #   print(df['State'][i])\n",
    "                    print(\"Used Google API\")\n",
    "        else:                                           #this is if zip is not unique\n",
    "            all_names = df['State'][li]\n",
    "            all_names_set = set(all_names)\n",
    "          #  print(all_names_set)\n",
    "            if((len(all_names_set) == 1)and(next(iter(all_names_set))!=None)):    #if all has same City\n",
    "                df['State'][i] = all_names_set.pop()\n",
    "            else:                           #if different City\n",
    "                if(((search.by_zipcode(zzip)).State)!= None):\n",
    "                    df['State'][i] = ((search.by_zipcode(zzip)).State).upper()    #this will assign city using library                \n",
    "                else:\n",
    "                    a = get_state_by_api(zzip) #uses google api to get City\n",
    "                    if(a==\"ERROR\"):\n",
    "                        print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "                        df['State'][i] = \"NA\"\n",
    "                    else:\n",
    "                        df['State'][i] = a\n",
    "                        \n",
    "    elif(df['City'][i]!=None):            #This if is to identify on basis of City\n",
    "        city = df['City'][i] \n",
    "       # print(city)\n",
    "        li = list(df[df['City'] == city].index)\n",
    "        li.remove(i)\n",
    "       # print(li)\n",
    "        if(li == None):  # this is if the City is unique\n",
    "            a = get_state_by_api(city) #uses google api to get State\n",
    "            if(a==\"ERROR\"):\n",
    "                print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "                df['State'][i] = \"NA\"\n",
    "            else:\n",
    "                df['State'][i] = a\n",
    "                print(df['State'][i])\n",
    "                print(\"Used Google API\")\n",
    "        else:                                           #this is if City is not unique\n",
    "            all_names = df['State'][li]\n",
    "            all_names_set = set(all_names)\n",
    "        #    print(all_names_set)\n",
    "            if((len(all_names_set) == 1)and(next(iter(all_names_set))!=None)):    #if all has same State\n",
    "                df['State'][i] = all_names_set.pop()\n",
    "            else:                           #if different State\n",
    "                a = get_state_by_api(city) #uses google api to get State\n",
    "                if(a==\"ERROR\"):\n",
    "                    print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "                    df['State'][i] = \"NA\"\n",
    "                else:\n",
    "                    df['State'][i] = a                     \n",
    "                    \n",
    "    elif((df['Latitude'][i]!=None)and(df['Longitude'][i]!=None)):            #This if is to identify on basis of lat andlog\n",
    "        lat = df['Latitude'][i]\n",
    "        log = df['Longitude'][i]       \n",
    "        a = get_state_by_api_loc(lat,log) #uses google api to get State\n",
    "        if(a==\"ERROR\"):\n",
    "            print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "            df['State'][i] = \"NA\"\n",
    "        else:\n",
    "            df['State'][i] = a\n",
    "            print(df['State'][i])\n",
    "            print(\"Used Google API\")  \n",
    "            \n",
    "    elif(df['Address'][i]!=None):            #This if is to identify on basis of Address\n",
    "        add = df['Address'][i] \n",
    "      #  print(add)\n",
    "        li = list(df[df['Address'] == add].index)\n",
    "        li.remove(i)\n",
    "       # print(li)\n",
    "        if(li == None):  # this is if the Address is unique\n",
    "            a = get_state_by_api(add) #uses google api to get State\n",
    "            if(a==\"ERROR\"):\n",
    "                print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "                df['State'][i] = \"NA\"\n",
    "            else:\n",
    "                df['State'][i] = a\n",
    "       #         print(df['State'][i])\n",
    "                print(\"Used Google API\")\n",
    "        else:                                           #this is if Address is not unique\n",
    "            all_names = df['State'][li]\n",
    "            all_names_set = set(all_names)\n",
    "        #    print(all_names_set)\n",
    "            if((len(all_names_set) == 1)and(next(iter(all_names_set))!=None)):    #if all has same State\n",
    "                df['State'][i] = all_names_set.pop()\n",
    "            else:                           #if different State\n",
    "                a = get_state_by_api(add) #uses google api to get State\n",
    "                if(a==\"ERROR\"):\n",
    "                    print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "                    df['State'][i] = \"NA\"\n",
    "                else:\n",
    "                    df['State'][i] = a\n",
    "                    \n",
    "    else:\n",
    "        print(\"No data is there on the basis of which State can be found\")\n",
    "        print(\"So putting NA as a State\")\n",
    "        df['State'][i] = \"NA\"\n",
    "\n",
    "print(\"all Nulls are replaced for State Attribute\")\n",
    "#all null solved for State in df.\n",
    "df[df['State'].isnull()]\n",
    "#df[2003:2008]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Replacing all Nulls on Zip Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([4073], dtype='int64')\n",
      "API USED\n",
      "All Nulls have been replaced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inspection ID</th>\n",
       "      <th>DBA Name</th>\n",
       "      <th>AKA Name</th>\n",
       "      <th>License #</th>\n",
       "      <th>Facility Type</th>\n",
       "      <th>Risk</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Inspection Date</th>\n",
       "      <th>Inspection Type</th>\n",
       "      <th>Results</th>\n",
       "      <th>Violations</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Inspection ID, DBA Name, AKA Name, License #, Facility Type, Risk, Address, City, State, Zip, Inspection Date, Inspection Type, Results, Violations, Latitude, Longitude, Location]\n",
       "Index: []"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detection for zip\n",
    "null_index_Zip = df[df['Zip'].isnull()].index\n",
    "print(null_index_Zip)\n",
    "\n",
    "# removing nulls from Zip\n",
    "\n",
    "for i in null_index_Zip:\n",
    "    \n",
    "    if((df['Latitude'][i]!=None)and(df['Longitude'][i]!=None)):   #This if is to identify on basis of Lat and log\n",
    "        lat = df['Latitude'][i]\n",
    "        log = df['Longitude'][i]        \n",
    "        li = list(df[(df['Latitude'] == lat)&(df['Longitude']==log)].index)\n",
    "       # print(li)\n",
    "        li.remove(i)\n",
    "        #print(li)   \n",
    "        if(li == None):  # this is if the Lat long is new\n",
    "            a = get_zip_by_api_loc(lat,log) #uses google api to get State\n",
    "            if(a==\"ERROR\"):\n",
    "                print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "                df['Zip'][i] = \"NA\"\n",
    "            else:\n",
    "                df['Zip'][i] = a\n",
    "        #        print(df['Zip'][i])\n",
    "                print(\"Used Google API\")              \n",
    "        else:                                           #this is if lat & long is not unique\n",
    "            all_names = df['Zip'][li]\n",
    "            all_names_set = set(all_names)\n",
    "         #   print(all_names_set)\n",
    "            if((len(all_names_set) == 1)and(next(iter(all_names_set))!=None)):    #if all has same Zip\n",
    "                df['Zip'][i] = all_names_set.pop()\n",
    "            else:                           #if different Zip\n",
    "                a = get_zip_by_api_loc(lat,log) #uses google api to get Zip\n",
    "                if(a==\"ERROR\"):\n",
    "                    print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "                    df['Zip'][i] = \"NA\"\n",
    "                else:\n",
    "                    df['Zip'][i] = a\n",
    "           #         print(df['Zip'][i])\n",
    "                    print(\"Used Google API\")             \n",
    "                    \n",
    "                    \n",
    "    elif(df['Address'][i]!=None):            #This if is to identify on basis of Address\n",
    "        add = df['Address'][i]\n",
    "     #   print(add)\n",
    "        li = list(df[df['Address'] == add].index)\n",
    "        li.remove(i)\n",
    "      #  print(li)\n",
    "        if(li == None):  # this is if the Address is unique\n",
    "            a = get_zip_by_api(add) #uses google api to get Zip\n",
    "            if(a==\"ERROR\"):\n",
    "                print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "                df['Zip'][i] = \"NA\"\n",
    "            else:\n",
    "                df['Zip'][i] = a\n",
    "       #         print(df['Zip'][i])\n",
    "                print(\"Used Google API\")\n",
    "        else:                                           #this is if Address is not unique\n",
    "            all_names = df['Zip'][li]\n",
    "            all_names_set = set(all_names)\n",
    "        #    print(all_names_set)\n",
    "            if((len(all_names_set) == 1)and(next(iter(all_names_set))!=None)):    #if all has same Zip\n",
    "                df['Zip'][i] = all_names_set.pop()\n",
    "            else:                           #if different Zip\n",
    "                a = get_zip_by_api(add) #uses google api to get Zip\n",
    "                if(a==\"ERROR\"):\n",
    "                    print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "                    df['Zip'][i] = \"NA\"\n",
    "                else:\n",
    "                    df['Zip'][i] = a\n",
    "                    \n",
    "    else:\n",
    "        print(\"No data is there on the basis of which Zip can be found\")\n",
    "        print(\"So putting NA as a Zip\")\n",
    "        df['Zip'][i] = \"NA\"\n",
    "\n",
    "print(\"All Nulls have been replaced\")\n",
    "#all null solved for Zip in df.\n",
    "df[df['State'].isnull()]\n",
    "#df[4072:4075]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Replacing all Nulls on Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n",
      "ALL Nulls have been replaced\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: Longitude, dtype: object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#error8 null detection for Longitude\n",
    "null_index_Longitude = df[df['Longitude'].isnull()].index\n",
    "print(null_index_Longitude)\n",
    "\n",
    "#Error8 resolving null from Longitude\n",
    "for i in null_index_Longitude:    \n",
    "    \n",
    "    if(df['Location'][i]!=None):            #This is based on location attrribute\n",
    "        l = literal_eval(df['Location'][i])\n",
    "        df['Longitude'][i] = l[1]\n",
    "    \n",
    "    elif(df['Address'][i]!=None):            #This if is to identify on basis of Address\n",
    "        add = df['Address'][i]\n",
    "       # print(add)\n",
    "        li = list(df[df['Address'] == add].index)\n",
    "        li.remove(i)\n",
    "        #print(li)\n",
    "        if(li == None):  # this is if the Address is unique\n",
    "            a = get_longitude_by_api(add) #uses google api to get Zip\n",
    "         #   print(a)\n",
    "            if(a==\"ERROR\"):\n",
    "                print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "                df['Longitude'][i] = \"NA\"\n",
    "            else:\n",
    "                df['Longitude'][i] = a\n",
    "          #      print(df['Longitude'][i])\n",
    "                print(\"Used Google API\")\n",
    "        else:                                           #this is if Address is not unique\n",
    "            all_names = df['Longitude'][li]\n",
    "            all_names_set = set(all_names)\n",
    "           # print(all_names_set)\n",
    "            if((len(all_names_set) == 1)and(next(iter(all_names_set))!=None)):    #if all has same Longitude\n",
    "                df['Longitude'][i] = all_names_set.pop()\n",
    "            else:                                                           #if different lognitude\n",
    "                a = get_longitude_by_api(add) #uses google api to get lognitude\n",
    "                if(a==\"ERROR\"):\n",
    "                    print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "                    df['Longitude'][i] = \"NA\"\n",
    "                else:\n",
    "                    df['Longitude'][i] = a\n",
    "                    \n",
    "    else:\n",
    "        print(\"No data is there on the basis of which Longitude can be found\")\n",
    "        print(\"So putting NA as a Longitude\")\n",
    "        df['Longitude'][i] = \"NA\"\n",
    "        \n",
    "        \n",
    "        \n",
    "print(\"ALL Nulls have been replaced\")\n",
    "#nulls are replaced from Longitude\n",
    "df[df['Longitude'].isnull()]\n",
    "df['Longitude'][null_index_Longitude]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Replacing all Nulls on Latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 677, 1106, 1570, 2542, 2543, 2544, 2545, 2933, 2935, 2936, 3302,\n",
      "            4073, 4125, 4639],\n",
      "           dtype='int64')\n",
      "44.90925360000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.9082097\n",
      "41.7910494\n",
      "41.7804872\n",
      "41.7804872\n",
      "41.7804872\n",
      "41.7804872\n",
      "41.6919932\n",
      "41.7840205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.7918891\n",
      "43.3748799\n",
      "31.545172\n",
      "All Nulls have been replaced\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "677     44.90925360000001\n",
       "1106           41.9082097\n",
       "1570           41.7910494\n",
       "2542           41.7804872\n",
       "2543           41.7804872\n",
       "2544           41.7804872\n",
       "2545           41.7804872\n",
       "2933           41.6919932\n",
       "2935           41.7840205\n",
       "2936           41.7840205\n",
       "3302           34.7918891\n",
       "4073           43.3748799\n",
       "4125           41.7804872\n",
       "4639            31.545172\n",
       "Name: Latitude, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null detection for Latitude\n",
    "null_index_Latitude = df[df['Latitude'].isnull()].index\n",
    "print(null_index_Latitude)\n",
    "\n",
    "#Error7 resolving null from latitude\n",
    "for i in null_index_Latitude:\n",
    "#    print(df['Location'][i])\n",
    " #   print(df['Address'][i])\n",
    "    \n",
    "    if(df['Location'][i]!=None):            #This is based on location attrribute\n",
    "        l = literal_eval(df['Location'][i])\n",
    "        df['Latitude'][i] = l[0]\n",
    "    \n",
    "    elif(df['Address'][i]!=None):            #This if is to identify on basis of Address\n",
    "        add = df['Address'][i]\n",
    "   #     print(add)\n",
    "        li = list(df[df['Address'] == add].index)\n",
    "        li.remove(i)\n",
    "    #    print(li)\n",
    "        if(li == None):  # this is if the Address is unique\n",
    "            a = get_latitude_by_api(add) #uses google api to get latitude\n",
    "     #       print(a)\n",
    "            if(a==\"ERROR\"):\n",
    "                print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "                df['Latiude'][i] = \"NA\"\n",
    "            else:\n",
    "                df['Latitude'][i] = a\n",
    "      #          print(df['Latitude'][i])\n",
    "                print(\"Used Google API\")\n",
    "        else:                                           #this is if Address is not unique\n",
    "            all_names = df['Latitude'][li]\n",
    "            all_names_set = set(all_names)\n",
    "       #     print(all_names_set)\n",
    "            if((len(all_names_set) == 1)and(next(iter(all_names_set))!=None)):    #if all has same latitude\n",
    "                df['Latitude'][i] = all_names_set.pop()\n",
    "            else:                                                           #if different Latitude\n",
    "                a = get_latitude_by_api(add) #uses google api to get latitude\n",
    "                if(a==\"ERROR\"):\n",
    "                    print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "                    df['Latitude'][i] = \"NA\"\n",
    "                else:\n",
    "                    df['Latitude'][i] = a\n",
    "                    \n",
    "    else:\n",
    "        print(\"No data is there on the basis of which Latitude can be found\")\n",
    "        print(\"So putting NA as a Latitude\")\n",
    "        df['Latitude'][i] = \"NA\"\n",
    "        \n",
    "        \n",
    "print(\"All Nulls have been replaced\")\n",
    "#nulls are replaced from Latitude\n",
    "df[df['Latitude'].isnull()]\n",
    "df['Latitude'][null_index_Latitude]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Replacing all Nulls on Location Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 677, 1106, 1570, 2542, 2543, 2544, 2545, 2933, 2935, 2936, 3302,\n",
      "            4073, 4125, 4639],\n",
      "           dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All nulls have been replaced\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "677     (44.90925360000001,-92.99583009999999)\n",
       "1106                  (41.9082097,-87.7863824)\n",
       "1570           (41.7910494,-87.68944950000001)\n",
       "2542                  (41.7804872,-87.6422731)\n",
       "2543                  (41.7804872,-87.6422731)\n",
       "2544                  (41.7804872,-87.6422731)\n",
       "2545                  (41.7804872,-87.6422731)\n",
       "2933                  (41.6919932,-87.6660502)\n",
       "2935           (41.7840205,-87.68823599999999)\n",
       "2936           (41.7840205,-87.68823599999999)\n",
       "3302                  (34.7918891,-78.9692206)\n",
       "4073                  (43.3748799,-85.9840007)\n",
       "4125                  (41.7804872,-87.6422731)\n",
       "4639            (31.545172,-97.17109900000001)\n",
       "Name: Location, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#error9 null detection for Location\n",
    "null_index_Location = df[df['Location'].isnull()].index\n",
    "print(null_index_Location)\n",
    "\n",
    "for i in null_index_Location:    \n",
    "    location=\"\"\n",
    "    if((df['Latitude'][i]!=None)and(df['Longitude'][i]!=None)):   #This if is to identify on basis of Lat and log\n",
    "        location = \"(\"+df['Latitude'][i]+\",\"+df['Longitude'][i]+\")\"\n",
    "        df['Location'][i]= location\n",
    "    \n",
    "    elif(df['Address'][i]!=None):            #This if is to identify on basis of Address\n",
    "        add = df['Address'][i]\n",
    "        #print(add)\n",
    "        li = list(df[df['Address'] == add].index)\n",
    "        li.remove(i)\n",
    "        #print(li)\n",
    "        if(li == None):  # this is if the Address is unique\n",
    "            a = get_latitude_by_api(add) #uses google api to get latitude\n",
    "            b = get_longitude_by_api(add) #uses google api to get longitude\n",
    "         #   print(a)\n",
    "         #   print(b)\n",
    "            if((a==\"ERROR\")or(b == \"ERROR\")):\n",
    "                print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "                df['Location'][i] = \"NA\"\n",
    "            else:\n",
    "                df['Location'][i] = \"(\"+a+\",\"+b+\")\"\n",
    "          #      print(df['Location'][i])\n",
    "                print(\"Used Google API\")\n",
    "        else:                                           #this is if Address is not unique\n",
    "            all_names = df['Location'][li]\n",
    "            all_names_set = set(all_names)\n",
    "         #   print(all_names_set)\n",
    "            if((len(all_names_set) == 1)and(next(iter(all_names_set))!=None)):    #if all has same location\n",
    "                df['Location'][i] = all_names_set.pop()\n",
    "            else:                                                           #if different location\n",
    "                a = get_latitude_by_api(add) #uses google api to get latitude\n",
    "                b = get_longitude_by_api(add) #uses google api to get longitude                \n",
    "                if((a==\"ERROR\")or(b == \"ERROR\")):\n",
    "                    print(\"ERROR OCCURED FROM GOOGLEAPI\")\n",
    "                    df['Location'][i] = \"NA\"\n",
    "                else:\n",
    "                    df['Location'][i] = \"(\"+a+\",\"+b+\")\"\n",
    "          #          print(df['Location'][i])\n",
    "                    print(\"Used Google API\")\n",
    "                    \n",
    "    else:\n",
    "        print(\"No data is there on the basis of which Location can be found\")\n",
    "        print(\"So putting NA as a Location\")\n",
    "        df['Location'][i] = \"NA\"\n",
    "    \n",
    "\n",
    "print(\"All nulls have been replaced\")\n",
    "#nulls are replaced from Location\n",
    "#df[df['Location'].isnull()]\n",
    "df['Location'][null_index_Location]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Write DATA ON Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write output in output_DIW file\n",
    "writer = pd.ExcelWriter('output_DIW.xlsx')\n",
    "df.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
